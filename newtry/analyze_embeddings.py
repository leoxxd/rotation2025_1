#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æç”Ÿæˆçš„embeddingæ–‡ä»¶
"""

import numpy as np
import pickle
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import os

def analyze_embeddings():
    """åˆ†æembeddingæ–‡ä»¶"""
    
    # 1. è¯»å–æ•°æ®
    print("è¯»å–embeddingæ•°æ®...")
    embeddings = np.load('./embeddings_output/image_embeddings.npy')
    
    with open('./embeddings_output/metadata.pkl', 'rb') as f:
        metadata = pickle.load(f)
    
    # 2. åŸºæœ¬ä¿¡æ¯
    print("\n" + "="*50)
    print("åŸºæœ¬ä¿¡æ¯:")
    print(f"å›¾åƒæ•°é‡: {embeddings.shape[0]}")
    print(f"Embeddingç»´åº¦: {embeddings.shape[1]}")
    print(f"æ•°æ®ç±»å‹: {embeddings.dtype}")
    print(f"å†…å­˜å¤§å°: {embeddings.nbytes / (1024*1024):.2f} MB")
    print("="*50)
    
    # 3. ç»Ÿè®¡ä¿¡æ¯
    print("\nç»Ÿè®¡ä¿¡æ¯:")
    print(f"æœ€å°å€¼: {embeddings.min():.4f}")
    print(f"æœ€å¤§å€¼: {embeddings.max():.4f}")
    print(f"å¹³å‡å€¼: {embeddings.mean():.4f}")
    print(f"æ ‡å‡†å·®: {embeddings.std():.4f}")
    
    # 4. æŸ¥çœ‹å‰å‡ å¼ å›¾åƒçš„ä¿¡æ¯
    print("\nå‰3å¼ å›¾åƒä¿¡æ¯:")
    for i in range(min(3, len(metadata['image_ids']))):
        print(f"\nå›¾åƒ {i+1}:")
        print(f"  å›¾åƒID: {metadata['image_ids'][i]}")
        print(f"  Captions:")
        for j, caption in enumerate(metadata['captions_per_image'][i]):
            print(f"    {j+1}. {caption}")
        print(f"  Embeddingå½¢çŠ¶: {embeddings[i].shape}")
        print(f"  Embeddingå‰5ä¸ªå€¼: {embeddings[i][:5]}")
    
    return embeddings, metadata

def visualize_embeddings(embeddings, metadata, n_samples=100):
    """å¯è§†åŒ–embeddings"""
    
    print(f"\nç”Ÿæˆå¯è§†åŒ–å›¾ï¼ˆä½¿ç”¨å‰{n_samples}ä¸ªæ ·æœ¬ï¼‰...")
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    indices = np.random.choice(len(embeddings), min(n_samples, len(embeddings)), replace=False)
    sample_embeddings = embeddings[indices]
    sample_captions = [metadata['captions_per_image'][i][0] for i in indices]  # å–ç¬¬ä¸€ä¸ªcaption
    
    # PCAé™ç»´
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(sample_embeddings)
    
    # åˆ›å»ºå¯è§†åŒ–
    plt.figure(figsize=(15, 10))
    
    # ä¸»å›¾
    plt.subplot(2, 2, 1)
    scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7, c=range(len(pca_result)), cmap='viridis')
    plt.colorbar(scatter)
    plt.title(f'PCA Visualization (å‰{n_samples}ä¸ªæ ·æœ¬)')
    plt.xlabel(f'PC1 (è§£é‡Šæ–¹å·®: {pca.explained_variance_ratio_[0]:.2%})')
    plt.ylabel(f'PC2 (è§£é‡Šæ–¹å·®: {pca.explained_variance_ratio_[1]:.2%})')
    
    # æ·»åŠ ä¸€äº›captionæ ‡ç­¾
    for i in range(0, len(sample_captions), max(1, len(sample_captions)//10)):
        plt.annotate(sample_captions[i][:30] + '...' if len(sample_captions[i]) > 30 else sample_captions[i], 
                    (pca_result[i, 0], pca_result[i, 1]), 
                    fontsize=8, alpha=0.8)
    
    # Embeddingåˆ†å¸ƒ
    plt.subplot(2, 2, 2)
    plt.hist(embeddings.flatten(), bins=50, alpha=0.7)
    plt.title('Embeddingå€¼åˆ†å¸ƒ')
    plt.xlabel('å€¼')
    plt.ylabel('é¢‘æ¬¡')
    
    # æ¯å¼ å›¾åƒembeddingçš„L2èŒƒæ•°
    plt.subplot(2, 2, 3)
    norms = np.linalg.norm(embeddings, axis=1)
    plt.hist(norms, bins=30, alpha=0.7)
    plt.title('æ¯å¼ å›¾åƒembeddingçš„L2èŒƒæ•°åˆ†å¸ƒ')
    plt.xlabel('L2èŒƒæ•°')
    plt.ylabel('é¢‘æ¬¡')
    
    # ç»´åº¦é‡è¦æ€§ï¼ˆå‰20ä¸ªç»´åº¦ï¼‰
    plt.subplot(2, 2, 4)
    dim_variance = np.var(embeddings, axis=0)
    top_dims = np.argsort(dim_variance)[-20:]
    plt.bar(range(20), dim_variance[top_dims])
    plt.title('å‰20ä¸ªæœ€é‡è¦ç»´åº¦çš„æ–¹å·®')
    plt.xlabel('ç»´åº¦æ’å')
    plt.ylabel('æ–¹å·®')
    
    plt.tight_layout()
    plt.savefig('./embeddings_output/embedding_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… å¯è§†åŒ–å›¾å·²ä¿å­˜åˆ°: ./embeddings_output/embedding_analysis.png")

def find_similar_images(embeddings, metadata, query_idx=0, top_k=5):
    """æ‰¾åˆ°ç›¸ä¼¼çš„å›¾åƒ"""
    
    print(f"\næŸ¥æ‰¾ä¸å›¾åƒ {query_idx} æœ€ç›¸ä¼¼çš„å›¾åƒ...")
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    from sklearn.metrics.pairwise import cosine_similarity
    
    query_embedding = embeddings[query_idx:query_idx+1]
    similarities = cosine_similarity(query_embedding, embeddings)[0]
    
    # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å›¾åƒï¼ˆæ’é™¤è‡ªå·±ï¼‰
    similar_indices = np.argsort(similarities)[::-1][1:top_k+1]
    
    print(f"\næŸ¥è¯¢å›¾åƒ {query_idx}:")
    print(f"å›¾åƒID: {metadata['image_ids'][query_idx]}")
    print("Captions:")
    for i, caption in enumerate(metadata['captions_per_image'][query_idx]):
        print(f"  {i+1}. {caption}")
    
    print(f"\næœ€ç›¸ä¼¼çš„ {top_k} å¼ å›¾åƒ:")
    for i, idx in enumerate(similar_indices):
        similarity = similarities[idx]
        print(f"\n{i+1}. å›¾åƒ {idx} (ç›¸ä¼¼åº¦: {similarity:.4f})")
        print(f"   å›¾åƒID: {metadata['image_ids'][idx]}")
        print("   Captions:")
        for j, caption in enumerate(metadata['captions_per_image'][idx]):
            print(f"     {j+1}. {caption}")

def main():
    """ä¸»å‡½æ•°"""
    
    print("å¼€å§‹åˆ†æembeddingæ–‡ä»¶...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists('./embeddings_output/image_embeddings.npy'):
        print("âŒ æ‰¾ä¸åˆ°embeddingæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œä¸»è„šæœ¬ç”Ÿæˆembeddings")
        return
    
    # åˆ†ææ•°æ®
    embeddings, metadata = analyze_embeddings()
    
    # å¯è§†åŒ–
    visualize_embeddings(embeddings, metadata)
    
    # æŸ¥æ‰¾ç›¸ä¼¼å›¾åƒ
    find_similar_images(embeddings, metadata)
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
